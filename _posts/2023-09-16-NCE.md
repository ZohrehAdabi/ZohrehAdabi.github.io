---
title: 'Noise Contrastive estimation'
date: 2023-09-16
permalink: /posts/2023/09/NCE/
tags:
  - NCE
  - unnormalized
  - MLE
---

Explaining the approximation methods of maximum likelihood, supervised density estimation, and the main idea of the NCE paper.

Assumption
======
$p_d$: data disribution <br>
$p_m$: model disribution <br>
$p_n$: auxiliary (noise) disribution <br>
<br>
$p_m = \frac{f_m}{Z_m}$

Estimation of unnormalized statistical models
======

### Maximum likelihood
$max \; J(\theta)=log \; p_m(x)$<br>

### [Monte Carlo maximum likelihood](https://www.jstor.org/stable/4616738)
$J(\theta)=log \; f_m - log\; \mathbb{E}_{p_n}[\frac{f_m}{p_n}]$<br>


### [Contrastive divergence](https://direct.mit.edu/neco/article-abstract/14/8/1771/6687/Training-Products-of-Experts-by-Minimizing?redirectedFrom=fulltext)

$ \partial_{\theta} J(\theta)= \mathbb{E_{p_d}} [ \partial_{\theta}\; log \; f_m] - \mathbb{E_{p_m}} [ \partial_{\theta}\; log \; f_m]$ <br> 

### [Score matching](https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf)
$J(\theta)= \mathbb{E_{p_d}}[||\nabla_{x} \; log\; f_m ||^2 + 2 \nabla_{x}^2 \; log\; f_m ]$
<br>

Unsupervised as supervised learning [^1]
======
#### learning likelihood ratio $\frac{p_m(u)}{p_n(u)}$

`real/data calss: C=1`  <br>
`fake/noise class: C=0`  <br>
$T_d$: # data,  $T_d$: # noise <br>

$ p(u\|C=1)=p_m(u), \;\; p(u\|c=0)=p_n(u)$ , \;\; $\nu=\frac{T_n}{T_d}$<br>

$ p(C=1\|u)= \frac{p(u\|C=1)p(C=1)}{p(u)}= \frac{p_m(u)}{p_m(u) + \nu p_n(u)}$ <br>
$ p(C=0\|u)= \frac{\nu p_n(u)}{p_m(u) + \nu p_n(u)} = 1-p(C=1\|u)$ <br>
#### logistic regression <br>
$h(u)= p(C=1\|u)=\frac{p_m(u)}{p_m(u) + \nu p_n(u)}=\frac{1}{1 + \nu \frac{p_n(u)}{p_m(u)}}=\frac{1}{1 + \nu exp(-g(u))}$ <br>
$g(u)=log\; \frac{p_m(u)}{p_n(u)}$ <br>

Noise contrastive estimation [paper](https://jmlr.org/papers/volume13/gutmann12a/gutmann12a.pdf)
======
$f_m \text{with parameter} \; \alpha$  <br>
Main Idea: learn $Z_m$ as an additional parameter not as a function of $\alpha$. <br>
<br>



---

[^1]: 2009-Springer-The Elements of Statistical Learning (Chapter 14.2.4, pp. 495â€“497),